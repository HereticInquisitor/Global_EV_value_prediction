{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import FeatureHasher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  trials.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('data/Global_EV_2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>category</th>\n",
       "      <th>parameter</th>\n",
       "      <th>mode</th>\n",
       "      <th>powertrain</th>\n",
       "      <th>year</th>\n",
       "      <th>unit</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Historical</td>\n",
       "      <td>EV stock</td>\n",
       "      <td>Cars</td>\n",
       "      <td>BEV</td>\n",
       "      <td>2011</td>\n",
       "      <td>Vehicles</td>\n",
       "      <td>49.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Historical</td>\n",
       "      <td>EV sales share</td>\n",
       "      <td>Cars</td>\n",
       "      <td>EV</td>\n",
       "      <td>2011</td>\n",
       "      <td>percent</td>\n",
       "      <td>0.00650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Historical</td>\n",
       "      <td>EV stock share</td>\n",
       "      <td>Cars</td>\n",
       "      <td>EV</td>\n",
       "      <td>2011</td>\n",
       "      <td>percent</td>\n",
       "      <td>0.00046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Historical</td>\n",
       "      <td>EV sales</td>\n",
       "      <td>Cars</td>\n",
       "      <td>BEV</td>\n",
       "      <td>2011</td>\n",
       "      <td>Vehicles</td>\n",
       "      <td>49.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Historical</td>\n",
       "      <td>EV sales</td>\n",
       "      <td>Cars</td>\n",
       "      <td>BEV</td>\n",
       "      <td>2012</td>\n",
       "      <td>Vehicles</td>\n",
       "      <td>170.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      region    category       parameter  mode powertrain  year      unit  \\\n",
       "0  Australia  Historical        EV stock  Cars        BEV  2011  Vehicles   \n",
       "1  Australia  Historical  EV sales share  Cars         EV  2011   percent   \n",
       "2  Australia  Historical  EV stock share  Cars         EV  2011   percent   \n",
       "3  Australia  Historical        EV sales  Cars        BEV  2011  Vehicles   \n",
       "4  Australia  Historical        EV sales  Cars        BEV  2012  Vehicles   \n",
       "\n",
       "       value  \n",
       "0   49.00000  \n",
       "1    0.00650  \n",
       "2    0.00046  \n",
       "3   49.00000  \n",
       "4  170.00000  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols=[]\n",
    "num_cols=[]\n",
    "for cols in df.columns:\n",
    "    if df[cols].dtype==\"object\":\n",
    "        cat_cols.append(cols)\n",
    "    else:\n",
    "        num_cols.append(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['year', 'value']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region', 'category', 'parameter', 'mode', 'powertrain', 'unit']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for cat in cat_cols:\n",
    "    print(df[cat].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for cat in num_cols:\n",
    "    print(df[cat].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region        38\n",
       "category       3\n",
       "parameter      8\n",
       "mode           5\n",
       "powertrain     5\n",
       "unit           6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cat_cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region\n",
      "['Australia' 'Austria' 'Belgium' 'Brazil' 'Canada' 'Chile' 'China'\n",
      " 'Denmark' 'EU27' 'Europe' 'Finland' 'France' 'Germany' 'Greece' 'Iceland'\n",
      " 'India' 'Indonesia' 'Israel' 'Italy' 'Japan' 'Korea' 'Mexico'\n",
      " 'Netherlands' 'New Zealand' 'Norway' 'Other Europe' 'Poland' 'Portugal'\n",
      " 'Rest of the world' 'South Africa' 'Spain' 'Sweden' 'Switzerland'\n",
      " 'Thailand' 'Turkiye' 'United Kingdom' 'USA' 'World']\n",
      "\n",
      "category\n",
      "['Historical' 'Projection-STEPS' 'Projection-APS']\n",
      "\n",
      "parameter\n",
      "['EV stock' 'EV sales share' 'EV stock share' 'EV sales'\n",
      " 'EV charging points' 'Electricity demand' 'Oil displacement Mbd'\n",
      " 'Oil displacement, million lge']\n",
      "\n",
      "mode\n",
      "['Cars' 'EV' 'Buses' 'Vans' 'Trucks']\n",
      "\n",
      "powertrain\n",
      "['BEV' 'EV' 'PHEV' 'Publicly available fast' 'Publicly available slow']\n",
      "\n",
      "unit\n",
      "['Vehicles' 'percent' 'charging points' 'GWh' 'Milion barrels per day'\n",
      " 'Oil displacement, million lge']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cols in cat_cols:\n",
    "    print(cols)\n",
    "    print(df[cols].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Samples can not be a single string. The input must be an iterable over iterables of strings.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ayush/Ayush/Sixth_Sem/ML/ML_project/research/trials.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ayush/Ayush/Sixth_Sem/ML/ML_project/research/trials.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m column_data \u001b[39m=\u001b[39m df[[column_to_encode]]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ayush/Ayush/Sixth_Sem/ML/ML_project/research/trials.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# 4. Apply hash encoding to the column and convert to a sparse matrix\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ayush/Ayush/Sixth_Sem/ML/ML_project/research/trials.ipynb#X20sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m hashed_features \u001b[39m=\u001b[39m hasher\u001b[39m.\u001b[39;49mtransform(df[[column_to_encode]])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ayush/Ayush/Sixth_Sem/ML/ML_project/research/trials.ipynb#X20sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# 5. Optionally, convert the sparse matrix to a DataFrame\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ayush/Ayush/Sixth_Sem/ML/ML_project/research/trials.ipynb#X20sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m hashed_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(hashed_features\u001b[39m.\u001b[39mtoarray())\n",
      "File \u001b[0;32m~/Ayush/Sixth_Sem/ML/myenv/lib/python3.10/site-packages/sklearn/utils/_set_output.py:273\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    272\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 273\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    274\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    275\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    276\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    277\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    278\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    279\u001b[0m         )\n",
      "File \u001b[0;32m~/Ayush/Sixth_Sem/ML/myenv/lib/python3.10/site-packages/sklearn/feature_extraction/_hash.py:172\u001b[0m, in \u001b[0;36mFeatureHasher.transform\u001b[0;34m(self, raw_X)\u001b[0m\n\u001b[1;32m    170\u001b[0m first_raw_X \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(raw_X)\n\u001b[1;32m    171\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(first_raw_X, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 172\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    173\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSamples can not be a single string. The input must be an iterable\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m over iterables of strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m     )\n\u001b[1;32m    176\u001b[0m raw_X_ \u001b[39m=\u001b[39m chain([first_raw_X], raw_X)\n\u001b[1;32m    177\u001b[0m raw_X \u001b[39m=\u001b[39m (((f, \u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m raw_X_)\n",
      "\u001b[0;31mValueError\u001b[0m: Samples can not be a single string. The input must be an iterable over iterables of strings."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 2. Specify the column you want to hash encode\n",
    "column_to_encode = \"category\"\n",
    "\n",
    "# 3. Instantiate FeatureHasher with the desired number of features\n",
    "n_features = 64  # Adjust this value as needed\n",
    "hasher = FeatureHasher(n_features=n_features, input_type=\"string\")\n",
    "column_data = df[[column_to_encode]].values.tolist()\n",
    "\n",
    "# 4. Apply hash encoding to the column and convert to a sparse matrix\n",
    "hashed_features = hasher.transform(column_data)\n",
    "\n",
    "# 5. Optionally, convert the sparse matrix to a DataFrame\n",
    "hashed_df = pd.DataFrame(hashed_features.toarray())\n",
    "\n",
    "# 6. Concatenate the original DataFrame with the hash-encoded features\n",
    "data_encoded = pd.concat([df, hashed_df], axis=1)\n",
    "\n",
    "# 7. Optionally, drop the original categorical column\n",
    "data_encoded.drop(columns=[column_to_encode], inplace=True)\n",
    "\n",
    "# 8. Now data_encoded contains the original dataset with hash-encoded features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasher=FeatureHasher(n_features=64, input_type=\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Samples can not be a single string. The input must be an iterable over iterables of strings.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ayush/Ayush/Sixth_Sem/ML/ML_project/research/trials.ipynb Cell 13\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ayush/Ayush/Sixth_Sem/ML/ML_project/research/trials.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# df=hasher.transform(df[[cat_cols]])\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ayush/Ayush/Sixth_Sem/ML/ML_project/research/trials.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m hasher\u001b[39m.\u001b[39mfit(df[\u001b[39m'\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ayush/Ayush/Sixth_Sem/ML/ML_project/research/trials.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39m hasher\u001b[39m.\u001b[39;49mtransform(df[\u001b[39m'\u001b[39;49m\u001b[39mcategory\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ayush/Ayush/Sixth_Sem/ML/ML_project/research/trials.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m df\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/Ayush/Sixth_Sem/ML/myenv/lib/python3.10/site-packages/sklearn/utils/_set_output.py:273\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    272\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 273\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    274\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    275\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    276\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    277\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    278\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    279\u001b[0m         )\n",
      "File \u001b[0;32m~/Ayush/Sixth_Sem/ML/myenv/lib/python3.10/site-packages/sklearn/feature_extraction/_hash.py:172\u001b[0m, in \u001b[0;36mFeatureHasher.transform\u001b[0;34m(self, raw_X)\u001b[0m\n\u001b[1;32m    170\u001b[0m first_raw_X \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(raw_X)\n\u001b[1;32m    171\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(first_raw_X, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 172\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    173\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSamples can not be a single string. The input must be an iterable\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m over iterables of strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m     )\n\u001b[1;32m    176\u001b[0m raw_X_ \u001b[39m=\u001b[39m chain([first_raw_X], raw_X)\n\u001b[1;32m    177\u001b[0m raw_X \u001b[39m=\u001b[39m (((f, \u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m raw_X_)\n",
      "\u001b[0;31mValueError\u001b[0m: Samples can not be a single string. The input must be an iterable over iterables of strings."
     ]
    }
   ],
   "source": [
    "# df=hasher.transform(df[[cat_cols]])\n",
    "hasher.fit(df['category'])\n",
    "df['category']= hasher.transform(df['category'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
